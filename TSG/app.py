import argparse
import os
import sys
import tempfile
from glob import glob
from typing import Any, Union

import numpy as np
import torch
import trimesh
from PIL import Image

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from triposg.pipelines.pipeline_triposg import TripoSGPipeline
from image_process import prepare_image
from briarmbg import BriaRMBG
import pymeshlab
import gradio as gr

# æ¨¡å‹æƒé‡ç›®å½•
TRI_POSG_WEIGHTS_DIR = "D:\work\AUTO1111\webui\TripoSG\pretrained_weights\TripoSG"
RMBG_WEIGHTS_DIR = "D:\work\AUTO1111\webui\TripoSG\pretrained_weights\RMBG-1.4"

# ========== åŸå§‹æ¨ç†é€»è¾‘ä¿ç•™ ==========
@torch.no_grad()
def run_triposg(
    pipe,
    image_input,
    rmbg_net,
    seed: int,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.0,
    faces: int = -1,
) -> trimesh.Trimesh:

    img_pil = prepare_image(image_input, bg_color=np.array([1.0, 1.0, 1.0]), rmbg_net=rmbg_net)

    outputs = pipe(
        image=img_pil,
        generator=torch.Generator(device=pipe.device).manual_seed(seed),
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
    ).samples[0]

    mesh = trimesh.Trimesh(outputs[0].astype(np.float32), np.ascontiguousarray(outputs[1]))

    if faces > 0:
        mesh = simplify_mesh(mesh, faces)

    return mesh

def mesh_to_pymesh(vertices, faces):
    mesh = pymeshlab.Mesh(vertex_matrix=vertices, face_matrix=faces)
    ms = pymeshlab.MeshSet()
    ms.add_mesh(mesh)
    return ms

def pymesh_to_trimesh(mesh):
    verts = mesh.vertex_matrix()
    faces = mesh.face_matrix()
    return trimesh.Trimesh(vertices=verts, faces=faces)

def simplify_mesh(mesh: trimesh.Trimesh, n_faces):
    if mesh.faces.shape[0] > n_faces:
        ms = mesh_to_pymesh(mesh.vertices, mesh.faces)
        ms.meshing_merge_close_vertices()
        ms.meshing_decimation_quadric_edge_collapse(targetfacenum=n_faces)
        return pymesh_to_trimesh(ms.current_mesh())
    else:
        return mesh

# ========== åˆå§‹åŒ–æ¨¡å‹ ==========
device = "cuda"
dtype = torch.float16

rmbg_net = BriaRMBG.from_pretrained(RMBG_WEIGHTS_DIR).to(device)
rmbg_net.eval()
pipe: TripoSGPipeline = TripoSGPipeline.from_pretrained(TRI_POSG_WEIGHTS_DIR).to(device, dtype)

# ========== Gradio åŒ…è£… ==========
def inference_ui(image, seed, steps, guidance, faces):
    mesh = run_triposg(
        pipe,
        image_input=image,
        rmbg_net=rmbg_net,
        seed=int(seed),
        num_inference_steps=int(steps),
        guidance_scale=float(guidance),
        faces=int(faces),
    )

    # ä¸´æ—¶æ–‡ä»¶å†™å…¥ GLB
    tmp_file = tempfile.NamedTemporaryFile(suffix=".glb", delete=False)
    mesh.export(tmp_file.name)
    tmp_file.close()

    # è¿”å›æ–‡ä»¶è·¯å¾„ç»™ Model3D å’Œ File
    return tmp_file.name, tmp_file.name

with gr.Blocks() as demo:
    gr.Markdown("## ğŸŸ¢ TripoSG ")
    with gr.Row():
        with gr.Column():
            image = gr.Image(type="pil", label="è¾“å…¥å›¾ç‰‡")
            seed = gr.Number(value=42, label="éšæœºç§å­")
            steps = gr.Slider(10, 100, value=50, step=1, label="æ¨ç†æ­¥æ•°")
            guidance = gr.Slider(1, 15, value=7.0, step=0.5, label="Guidance Scale")
            faces = gr.Number(value=-1, label="ç›®æ ‡é¢æ•° (<=0 ä¸ç®€åŒ–)")
            btn = gr.Button("ç”Ÿæˆæ¨¡å‹")
        with gr.Column():
            gr.Markdown("### é¢„è§ˆä¸ä¸‹è½½")
            model3d = gr.Model3D(label="GLB é¢„è§ˆ")
            download = gr.File(label="ä¸‹è½½ GLB")

    btn.click(
        fn=inference_ui,
        inputs=[image, seed, steps, guidance, faces],
        outputs=[model3d, download],
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
